"""
æ•°æ®å†™å…¥æ¨¡å—
è´Ÿè´£ ClickHouse åŸå­å†™å…¥ï¼ˆEXCHANGE TABLESï¼‰å’Œ SQLite å›é€€å†™å…¥ã€‚
"""

import os
import json
import datetime
import sqlite3

import clickhouse_connect


class DataWriter:
    """ClickHouse åŸå­å†™å…¥ + SQLite å›é€€"""

    # ClickHouse å»ºè¡¨ DDL
    TABLE_DDL = {
        "buy_fact": """
            CREATE TABLE IF NOT EXISTS buy_fact (
                date Date, user_id Int32, order_id String, item_id Int32,
                category_id Int32, price Decimal(10, 2), channel String, age_group String
            ) ENGINE = MergeTree() ORDER BY (date, user_id)
        """,
        "user_rfm": """
            CREATE TABLE IF NOT EXISTS user_rfm (
                user_id Int32, rfm_label String
            ) ENGINE = MergeTree() ORDER BY (user_id)
        """,
        "cohort_matrix": """
            CREATE TABLE IF NOT EXISTS cohort_matrix (
                cohort_date Date, day_diff Int32, active_users Int32, cohort_users Int32
            ) ENGINE = MergeTree() ORDER BY (cohort_date, day_diff)
        """,
        "user_funnel_mart": """
            CREATE TABLE IF NOT EXISTS user_funnel_mart (
                user_id Int32, has_pv Int32, has_cart Int32, has_buy Int32, date Date
            ) ENGINE = MergeTree() ORDER BY (user_id)
        """,
        "user_funnel_loose_mart": """
            CREATE TABLE IF NOT EXISTS user_funnel_loose_mart (
                user_id Int32, has_pv Int32, has_cart Int32, has_buy Int32, date Date
            ) ENGINE = MergeTree() ORDER BY (user_id)
        """,
        "etl_dq_log": """
            CREATE TABLE IF NOT EXISTS etl_dq_log (
                run_time DateTime,
                elapsed_seconds Float64,
                metrics String,
                warnings String,
                cluster_profiles String
            ) ENGINE = MergeTree() ORDER BY (run_time)
        """,
    }

    def __init__(self, config, dq):
        self.config = config
        self.dq = dq
        self.ch_available = False
        self.client = None

    def write_all(self, write_tasks):
        """
        [6/6] å†™å…¥æ•°æ®åº“ã€‚
        :param write_tasks: [(DataFrame, table_name), ...]
        """
        print("ğŸ’¾ [6/6] å†™å…¥æ•°æ®åº“...")
        self._detect_clickhouse()

        if self.ch_available:
            self._write_clickhouse(write_tasks)
        else:
            self._write_sqlite(write_tasks)

    def _detect_clickhouse(self):
        """å°è¯•è¿æ¥ ClickHouse"""
        try:
            self.client = clickhouse_connect.get_client(
                host=self.config["ch_host"],
                port=self.config["ch_port"],
                username=self.config["ch_user"],
                password=self.config["ch_password"],
            )
            self.client.command("SELECT 1")
            self.ch_available = True
            print("  âœ” ClickHouse è¿æ¥æˆåŠŸï¼Œä½¿ç”¨åŸå­å†™å…¥æ¨¡å¼")
        except Exception as e:
            print(f"  âš ï¸ ClickHouse ä¸å¯ç”¨ ({e})ï¼Œå›é€€åˆ° SQLite å†™å…¥")

    # â”€â”€ ClickHouse åŸå­å†™å…¥è·¯å¾„ â”€â”€

    def _write_clickhouse(self, write_tasks):
        """ClickHouse åŸå­å†™å…¥ï¼ˆEXCHANGE TABLES ç­–ç•¥ï¼‰"""
        # ç¡®ä¿æ‰€æœ‰è¡¨å­˜åœ¨
        for table_name, ddl in self.TABLE_DDL.items():
            self.client.command(ddl)
            print(f"  âœ” è¡¨ {table_name} å·²ç¡®ä¿å­˜åœ¨")

        # å†™å…¥ä¸šåŠ¡æ•°æ®
        for df_spark, table_name in write_tasks:
            self._write_atomic(df_spark, table_name)
            print(f"  âœ” {table_name} åŸå­å†™å…¥ ClickHouse å®Œæˆ")

        # å†™å…¥ DQ æŠ¥å‘Š
        self._write_dq_log_clickhouse()

    def _write_atomic(self, df, table_name):
        """å•è¡¨åŸå­å†™å…¥ï¼šå…ˆå†™ä¸´æ—¶è¡¨ï¼Œå† EXCHANGE"""
        tmp_table = f"{table_name}_tmp_new"
        self.client.command(f"DROP TABLE IF EXISTS {tmp_table}")
        self.client.command(f"CREATE TABLE {tmp_table} AS {table_name}")

        pdf = df.toPandas()
        self.client.insert_df(tmp_table, pdf)

        self.client.command(f"EXCHANGE TABLES {table_name} AND {tmp_table}")
        self.client.command(f"DROP TABLE IF EXISTS {tmp_table}")

    def _write_dq_log_clickhouse(self):
        """å°† DQ æŠ¥å‘Šå†™å…¥ ClickHouse etl_dq_log è¡¨"""
        try:
            dq_data = self.dq.to_json_dict()
            self.client.command(
                "INSERT INTO etl_dq_log (run_time, elapsed_seconds, metrics, warnings, cluster_profiles) "
                "VALUES ({rt:DateTime}, {el:Float64}, {mt:String}, {wn:String}, {cp:String})",
                parameters={
                    'rt': dq_data['run_time'],
                    'el': dq_data['elapsed_seconds'],
                    'mt': dq_data['metrics'],
                    'wn': dq_data['warnings'],
                    'cp': dq_data['cluster_profiles'],
                }
            )
            print("  âœ” æ•°æ®è´¨é‡æŠ¥å‘Šå·²å†™å…¥ etl_dq_log")
        except Exception as e:
            print(f"  âš ï¸ å†™å…¥ etl_dq_log å¤±è´¥: {e}")

    # â”€â”€ SQLite å›é€€è·¯å¾„ â”€â”€

    def _write_sqlite(self, write_tasks):
        """SQLite å›é€€å†™å…¥"""
        sqlite_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "ecommerce.db")
        sqlite_path = os.path.normpath(sqlite_path)
        print(f"  ğŸ“‚ SQLite å†™å…¥è·¯å¾„: {sqlite_path}")

        conn = sqlite3.connect(sqlite_path)

        for df_spark, table_name in write_tasks:
            pdf = df_spark.toPandas()
            conn.execute(f"DROP TABLE IF EXISTS {table_name}")
            pdf.to_sql(table_name, conn, if_exists="replace", index=False)
            print(f"  âœ” {table_name} å·²å†™å…¥ SQLite ({len(pdf)} è¡Œ)")

        # åˆ›å»ºç´¢å¼•åŠ é€ŸæŸ¥è¯¢
        index_stmts = [
            "CREATE INDEX IF NOT EXISTS idx_buy_fact_date ON buy_fact(date)",
            "CREATE INDEX IF NOT EXISTS idx_buy_fact_user ON buy_fact(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_funnel_date ON user_funnel_mart(date)",
            "CREATE INDEX IF NOT EXISTS idx_cohort_date ON cohort_matrix(cohort_date)",
        ]
        for stmt in index_stmts:
            try:
                conn.execute(stmt)
            except Exception:
                pass
        conn.commit()
        conn.close()
        print("  âœ” SQLite ç´¢å¼•å·²å»ºç«‹")
